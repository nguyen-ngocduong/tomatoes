{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3919e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import transforms, datasets, models\n",
    "from eval_res import *\n",
    "from feature_extractor import *\n",
    "import cv2\n",
    "from skfuzzy.cluster import cmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ea0be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "train_data_path = '/home/nguyenngocduong/Documents/Python/tomatoes/PlantDoc-Dataset/train'\n",
    "test_data_path = '//home/nguyenngocduong/Documents/Python/tomatoes/PlantDoc-Dataset/test'\n",
    "print(len(os.listdir(train_data_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cf65242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tomato samples: 662\n"
     ]
    }
   ],
   "source": [
    "train_tomato_samples = []\n",
    "# Sắp xếp các folder theo tên\n",
    "for class_name in sorted(os.listdir(train_data_path)):\n",
    "    class_path = os.path.join(train_data_path, class_name)\n",
    "    if \"Tomato\" in class_name:\n",
    "        # Sắp xếp các ảnh trong mỗi folder nếu muốn có thứ tự ổn định hơn\n",
    "        for img_name in sorted(os.listdir(class_path)):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            train_tomato_samples.append(img_path)\n",
    "\n",
    "print(f\"Number of tomato samples: {len(train_tomato_samples)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c465c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tomato samples: 69\n"
     ]
    }
   ],
   "source": [
    "test_tomato_samples = []\n",
    "for class_name in sorted(os.listdir(test_data_path)):\n",
    "    class_path = os.path.join(test_data_path, class_name)\n",
    "    if \"Tomato\" in class_name:\n",
    "        for img_name in sorted(os.listdir(class_path)):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            test_tomato_samples.append(img_path)\n",
    "\n",
    "print(f\"Number of tomato samples: {len(test_tomato_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3822a",
   "metadata": {},
   "source": [
    "### tien xu ly anh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ffd34b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/nguyenngocduong/Documents/Python/tomatoes/tomato_clean/train/Tomato___Bacterial_spot/Tomato___Bacterial_spot_0000.jpg'\n",
    "#Buoc 1 chuyen anh sang sang khong gian mau L(do sang)\n",
    "image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "L_channel = image_lab[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f1697e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buoc 1 chuyen anh sang sang khong gian mau L(do sang)\n",
    "def remake_image_L(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    L_channel = image_lab[:, :, 0]\n",
    "    return L_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057b517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 2: Phân cụm ảnh L bằng FCM và visualize kết quả\n",
    "def fcm_segmentation(L_channel, n_clusters=3, visualize=True):\n",
    "    # 1. Reshape ảnh L thành vector 1D\n",
    "    data = L_channel.reshape(-1, 1).T.astype(np.float64)  # shape: (1, N)\n",
    "\n",
    "    # 2. Áp dụng FCM\n",
    "    cntr, u, _, _, _, _, _ = cmeans(data, c=n_clusters, m=2, error=0.005, maxiter=1000)\n",
    "\n",
    "    # 3. Lấy nhãn cụm có giá trị membership cao nhất cho mỗi pixel\n",
    "    cluster_labels = np.argmax(u, axis=0)  # shape: (N,)\n",
    "\n",
    "    # 4. Reshape lại về dạng ảnh\n",
    "    cluster_labels_img = cluster_labels.reshape(L_channel.shape)\n",
    "\n",
    "    # 5. Tìm cụm tương ứng với lá (thường là cụm có diện tích lớn nhất ở giữa ảnh)\n",
    "    h, w = L_channel.shape\n",
    "    center_mask = np.zeros_like(L_channel, dtype=np.uint8)\n",
    "    center_mask[h//4:3*h//4, w//4:3*w//4] = 1\n",
    "    center_labels = cluster_labels_img[center_mask == 1]\n",
    "\n",
    "    # Đếm số pixel mỗi cụm trong vùng trung tâm\n",
    "    unique, counts = np.unique(center_labels, return_counts=True)\n",
    "    leaf_cluster = unique[np.argmax(counts)]  # cụm có nhiều pixel nhất ở giữa ảnh → là lá\n",
    "\n",
    "    # 6. Tạo mask nhị phân\n",
    "    mask_leaf = (cluster_labels_img == leaf_cluster).astype(np.uint8)\n",
    "\n",
    "    # 7. Visualize nếu cần\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(L_channel, cmap='gray')\n",
    "        plt.title('Ảnh L (gốc)')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cluster_labels_img, cmap='jet')\n",
    "        plt.title('Ảnh sau phân cụm FCM')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(mask_leaf, cmap='gray')\n",
    "        plt.title('Mask lá cây')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return mask_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed315bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Bước 3: Thay nền bằng màu xám và hiển thị ảnh kết quả\n",
    "def replace_background_and_show(image, mask_leaf, background_color=(128, 128, 128), visualize = True):\n",
    "    # Đảm bảo mask có shape (H, W, 1) để broadcast\n",
    "    mask_3ch = np.repeat(mask_leaf[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    # Tạo ảnh nền màu xám\n",
    "    bg = np.full_like(image, background_color, dtype=np.uint8)\n",
    "\n",
    "    # Thay nền: nếu mask == 1 → giữ pixel gốc; mask == 0 → thay bằng màu xám\n",
    "    result = np.where(mask_3ch == 1, image, bg)\n",
    "\n",
    "    # Hiển thị ảnh gốc, mask, ảnh sau khi thay nền\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Ảnh gốc')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask_leaf, cmap='gray')\n",
    "        plt.title('Mask lá cây')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Sau khi thay nền bằng màu xám')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c716b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BƯỚC 4: Tăng độ tương phản vùng lá bằng CLAHE\n",
    "def enhance_leaf_contrast(image_clean, mask_leaf,visualize = True):\n",
    "    \"\"\"\n",
    "    Tang độ tương phản vùng lá bằng CLAHE\n",
    "    \"\"\"\n",
    "    lab = cv2.cvtColor(image_clean, cv2.COLOR_BGR2LAB)\n",
    "    l,a,b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    l[mask_leaf == 1] = l_clahe[mask_leaf == 1]\n",
    "\n",
    "    lab_clahe = cv2.merge((l, a, b))\n",
    "    image_final = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "    # ve minh hoa\n",
    "    if visualize:\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(cv2.cvtColor(image_clean, cv2.COLOR_BGR2RGB))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(cv2.cvtColor(image_final, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.title('Ảnh sau tiền xử lý')\n",
    "        plt.show()\n",
    "    return image_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab4ccd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BƯỚC 5: Resize và chuẩn hóa ảnh để phù hợp ViT\n",
    "def transform_for_ViT(image_final):\n",
    "    \"\"\" Resize va chuan hoa anh de phu hop voi ViT\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),         # Nếu ảnh đầu vào là NumPy\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),           # Từ [0,255] → [0,1]\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # ImageNet\n",
    "    ])\n",
    "    return transform(image_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15c4a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BƯỚC 6: Trích xuất embedding từ mô hình ViT\n",
    "def extract_embedding(image_tensor, model):\n",
    "    \"\"\"\n",
    "    Trich xuat embedding tu ViT\n",
    "    \"\"\"\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Chuyen ve (1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        features = model(image_tensor)  # Trich xuat\n",
    "    return features.squeeze(0)  # Ve lai ve (768,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ViT_model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "ViT_model.eval()  # Chuyen sang che do danh gia\n",
    "ViT_model.heads = torch.nn.Identity()\n",
    "embeddings = []\n",
    "image_paths = train_tomato_samples\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Đọc ảnh và tiền xử lý\n",
    "    image = cv2.imread(img_path)\n",
    "    # 1. Chuyển sang không gian L\n",
    "    L_channel = remake_image_L(img_path)\n",
    "    # 2. Phân cụm FCM để lấy mask lá\n",
    "    mask_leaf = fcm_segmentation(L_channel)\n",
    "    # 3. Thay nền bằng màu xám\n",
    "    image_clean = replace_background_and_show(image, mask_leaf, visualize=False)\n",
    "    # 4. Tăng độ tương phản vùng lá\n",
    "    image_final = enhance_leaf_contrast(image_clean, mask_leaf, visualize=False)\n",
    "    # 5. Resize và chuẩn hóa cho ViT\n",
    "    image_tensor = transform_for_ViT(image_final)\n",
    "    # 6. Trích xuất embedding\n",
    "    embedding = extract_embedding(image_tensor, ViT_model)\n",
    "    embeddings.append(embedding.cpu().numpy())\n",
    "\n",
    "embeddings = np.stack(embeddings)  # (num_images, 768)\n",
    "print(\"Shape of embeddings:\", embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
